# 我的开发环境配置

我有两台机器，一台是只有核显的轻薄本（称为x1c），另一台是有独显的游戏本（称为u-deb）。因此在两台机器上都可以编写代码，但是模型的训练只能在u-deb上进行。通过`nvidia-smi`命令可以得到其显卡配置，如下图，是显存为8G的4060，能够满足实验需要。  
![1](pictures/0.png)

我计划在碎片时间用x1c撰写初步的代码，在u-deb进行代码debug与程序调试，两台机器的进度通过**git**的push与pull来统一，尽可能每日更新进度。  

# 一阶段：基本代码阅读与补全

## 程序入口

一边运行程序、一边阅读代码是高效的，所以需要先让程序能够跑起来，而在这过程中会有许多环境依赖的问题，以及程序入口有些路径都需要逐项配置、修改。  

### 程序入口：mars.py  

根据README中的提示，程序入口位于*mars.py*文件。  
运行之前需要在指定路径（./cfgops）中存放一个文件，应以*c1.py*为模板。  

### 模型设置：c1.py  

其内部定义了一个名为*mcfg*的函数，接受一个名为tags的参数，根据后面可以推测这是一个字符串列表，后面会根据其内的字符串来匹配不同的模式。  
此外，还有一个数据建立的部分，应该是定义数据集路径。  

### 运行

维持*c1.py*中的配置，先运行看看，第一次提示缺少*torchvision*、*cv2*等包，用pip安装即可，可见在之前安装的torch包之外又追加了一系列新依赖。  

![1](pictures/1.png)  

> 搜索可知，pytorch生态中，torch包是主库，基本功能由其实现  
> 而torchvision包是特地为计算机视觉任务提供的附加库，提供了CV方向的额外功能  

再次运行，这次的报错是因为*mars.py*中默认给定的root存放路径没有修改，指向了一个不存在的系统根目录，所以会报错。  
着手对其进行修改，将其变为一个指定的本地目录。注意到其注释提示“*注意项目运行root不要放在代码路径下*”，没能理解，搜索结果如下。  

> 在模型运行时，会产生大量临时文件、缓存、模型输出  
> 如果将运行根目录root放在当前代码路径下（即我这里的Mars_Assignment），会使源代码与模型混在一起，一方面会占用大量空间，另一方面不符合程序设计的哲学  

所以需要在当前目录外创建一个运行文件夹来存放这些中间数据以及下载的数据集。  
我这里是另外创建*Mars_Assignment_Running*文件夹，将其路径设为root。  

然后再次运行，这次的报错依然是路径错误，一路溯源，就在于*c1.py*内部的数据集建立部分没有对应更改。将其按照结构与下载的数据集对应上即可，***但是发现下载来的数据集结构与给出的并不一样***，今天先到此结束。  

**5.7日**  
***

重新阅读实验手册，发现数据集在“*数据/项目初始代码下载*”部分已经给定链接，而不是到数据集作者官网下载原版没有分割的数据集。  
下载后，在*c1.py*文件内将数据集路径一一对应进行修改，无误后运行。  

终于，这次报错信息变为了**NotImplementedError: Backbone::__init__
**，说明函数入口的一些配置已经完成，成功进入程序，走到了需要补全的地方，接下来开始对代码进行补全。  

## 代码补全

### Backbone

根据报错信息
```
File"/home/liuzt/Documents/MD_learning/PR&ML_Assignment/Mars/Mars_Assignment/model/base/backbone.py", line 14, in __init__raise  
NotImplementedError("Backbone::__init__")
```
可知现在进入了**yolo**网络的Backbone层。在整体结构图上，这一部分的具体操作在左侧这一例，从原图像出发，经过不同的卷积层，最后得到四个*feat*。  

观察*backbone.py*代码，经查询，这是一个典型的pytorch构建自定义神经网络方式：  
> class Backbone(nn.Module) 这里是定义了一个新类，继承自神经网络的基类
> 因此只需要实现\_\_init\_\_函数来初始化、forward函数来定义前向传播逻辑即可

由于继承的*nn.Module*，可以方便的在自定义类中调用各种神经网络层、张量操作等。  

#### 基本单元：ConvModule

在结构图中可以看到，最基本的单元就是*ConvModule*卷积层模块，其组成是**Conv2d二维卷积 + BatchNorm2d归一化 + SiLU激活**。卷积与归一化都了解，但是SiLU激活函数并没有了解过，遂搜索。  
> 搜索发现，SiLU函数是"x*sigmoid(x)"，用于提高模型非线性表达能力。  
> 函数式为 x/(1+e^-x)  

了解这三样基本组成单元后就可以构建，三者都可以通过nn.来调用，然后经搜索，可以用nn.Sequential方法将几层聚合成为一个，调用时按照函数来用就行。如此，就可以再将ConvModule打包成一个函数来直接调用。  

#### CSPLayer_2Conv

是十分复杂的一个单元。  
输入很简单，就是一个布尔量add以及一个求和数n，只是内部复杂。  

在进入后，首先经过一个ConvModule，然后**就不太明白**：输出的应该只有一个c_out维，但是图上还另外分了0.5c_out给concat，以及一整个c_out维给split。  
搜索的结果说是只有一个出口，进入split，可是图中明明是两个。所以这里今天没能搞懂。  

继续往下，先用pass完成需要完成的函数占空，然后整体先构建起来。发现不知道“n=3*d”中d参数如何获取，也是一个问题。今天先这样结束。  

**5.8**  
***

关于昨天的第一个问题，查找资料得到yolov8的这张结构图有两种，原理一致，只是手册里这版的Neck和Head层在另一版里合成了一层。  

分析两图结构相同之处以及要表达的意义，再结合最后一层输入的形状0.5(n+2)cout，可以猜测手册里的这一版应该是代表将第一层输入完整的送到concat，只是表达的方式不好。  
这样就能够匹配上最后的形状，同时在意义上也实现了最后与原数据的concat。  

#### SPPF

这一层的detial中没有给定输出维度，在架构图中分析，发现其输入输出是同维的，所以根据输入给定输出即可。  

detial中的MaxPool2d层没有给定任何参数，但是查询nn.MaxPool2d的用法时发现其是需要参数的：  
> kernel_size: 池化窗口大小  
> stride: 步长（默认等于 kernel_size） 
> padding: 边缘补零  

由于可能是自定义，也可能是一个约定俗成的大小，继续搜索这一模块在yolov8中的特定用法，果然是在SPPF层的特定用法，具体参数是固定的，分别是kernel_size=5, stride=1, padding=2。  

这样写的意义要从SPPF这一层的作用说起。SPPF是“SPP Fast”的缩写，意思是“快速感受野拓展”，比SPP更轻量、快速，通过多个MaxPool池化级联、最后再和原始输入拼接来增加感受野与提取上下文信息。  
而参数设置成5,1,2的关键就在于可以保持输入与输出同维，使MaxPool可以在多层级联中复用。  

依然将其封装为可调用的函数。  

#### 返回结构

基本构建好forward函数，但是返回值的结构并不很清晰，是作为列表、字典或者元组？  
到时候到调用的地方查看一下即可，现在先空着。  

#### 调试验证

根据结构图编写完**Backbone**部分，接下来是用调试方法检验正确性。  
由于之前使用过gdb，所以对于pdb的操作有一定的接受性，根据教程在forward函数开头下断点，运行时却直接报了**Neck**部分的未编译错误。可能是因为要先将所有模块初始化后才会执行，将断点设在init函数开头，再次执行，发现的确在**Backbone**对象的初始化完毕后继续初始化Neck部分。所以只好先继续完成其余模块。  

其实这里也看出来心急之处，明明报错信息是init函数未编译，但是却将forward部分也一并补全了，最后还一时半会debug不了:(。  

此外，在这里利用调试还可以解决之前的另一个问题，也就是CSPLayer层的输入中，关于层数，其与模型参数d是有关的，但是给定的初始参数中没用过的只有n，而不是d。其实这里也就可以大胆判定n就是3xd，在调试模式用`p n`来查看n的值，为1。这的确是3xd。所以照此补全即可。  
（在后面看到*yolomodel.py*文件时，其注释也提到了“*note that n = 3 x d*”，所以考究的结果是正确的。）  

### Neck

紧接着是Neck部分代码的编写。  
虽然前面提到了心急，直接一整个模块编完，但是其实一整个编完也没有什么问题。  

5.11先到这里
***

#### 



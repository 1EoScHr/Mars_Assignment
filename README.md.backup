# 我的开发环境配置

我有两台机器，一台是只有核显的轻薄本（称为x1c），另一台是有独显的游戏本（称为u-deb）。因此在两台机器上都可以编写代码，但是模型的训练只能在u-deb上进行。通过`nvidia-smi`命令可以得到其显卡配置，如下图，是显存为8G的4060，能够满足实验需要。  
![1](pictures/0.png)

我计划在碎片时间用x1c撰写初步的代码，在u-deb进行代码debug与程序调试，两台机器的进度通过**git**的push与pull来统一，尽可能每日更新进度。  

# 一阶段：基本代码阅读与补全

## 程序入口

一边运行程序、一边阅读代码是高效的，所以需要先让程序能够跑起来，而在这过程中会有许多环境依赖的问题，以及程序入口有些路径都需要逐项配置、修改。  

### 程序入口：mars.py  

根据README中的提示，程序入口位于*mars.py*文件。  
运行之前需要在指定路径（./cfgops）中存放一个文件，应以*c1.py*为模板。  

### 模型设置：c1.py  

其内部定义了一个名为*mcfg*的函数，接受一个名为tags的参数，根据后面可以推测这是一个字符串列表，后面会根据其内的字符串来匹配不同的模式。  
此外，还有一个数据建立的部分，应该是定义数据集路径。  

### 运行

维持*c1.py*中的配置，先运行看看，第一次提示缺少*torchvision*、*cv2*等包，用pip安装即可，可见在之前安装的torch包之外又追加了一系列新依赖。  

![1](pictures/1.png)  

> 搜索可知，pytorch生态中，torch包是主库，基本功能由其实现  
> 而torchvision包是特地为计算机视觉任务提供的附加库，提供了CV方向的额外功能  

再次运行，这次的报错是因为*mars.py*中默认给定的root存放路径没有修改，指向了一个不存在的系统根目录，所以会报错。  
着手对其进行修改，将其变为一个指定的本地目录。注意到其注释提示“*注意项目运行root不要放在代码路径下*”，没能理解，搜索结果如下。  

> 在模型运行时，会产生大量临时文件、缓存、模型输出  
> 如果将运行根目录root放在当前代码路径下（即我这里的Mars_Assignment），会使源代码与模型混在一起，一方面会占用大量空间，另一方面不符合程序设计的哲学  

所以需要在当前目录外创建一个运行文件夹来存放这些中间数据以及下载的数据集。  
我这里是另外创建*Mars_Assignment_Running*文件夹，将其路径设为root。  

然后再次运行，这次的报错依然是路径错误，一路溯源，就在于*c1.py*内部的数据集建立部分没有对应更改。将其按照结构与下载的数据集对应上即可，***但是发现下载来的数据集结构与给出的并不一样***，今天先到此结束。  

**5.7日**  
***

重新阅读实验手册，发现数据集在“*数据/项目初始代码下载*”部分已经给定链接，而不是到数据集作者官网下载原版没有分割的数据集。  
下载后，在*c1.py*文件内将数据集路径一一对应进行修改，无误后运行。  

终于，这次报错信息变为了**NotImplementedError: Backbone::__init__
**，说明函数入口的一些配置已经完成，成功进入程序，走到了需要补全的地方，接下来开始对代码进行补全。  

## 代码补全

### Backbone

根据报错信息
```
File"/home/liuzt/Documents/MD_learning/PR&ML_Assignment/Mars/Mars_Assignment/model/base/backbone.py", line 14, in __init__raise  
NotImplementedError("Backbone::__init__")
```
可知现在进入了**yolo**网络的Backbone层。在整体结构图上，这一部分的具体操作在左侧这一例，从原图像出发，经过不同的卷积层，最后得到四个*feat*。  

观察*backbone.py*代码，经查询，这是一个典型的pytorch构建自定义神经网络方式：  
> class Backbone(nn.Module) 这里是定义了一个新类，继承自神经网络的基类
> 因此只需要实现\_\_init\_\_函数来初始化、forward函数来定义前向传播逻辑即可

由于继承的*nn.Module*，可以方便的在自定义类中调用各种神经网络层、张量操作等。  

#### 基本单元：ConvModule

在结构图中可以看到，最基本的单元就是*ConvModule*卷积层模块，其组成是**Conv2d二维卷积 + BatchNorm2d归一化 + SiLU激活**。卷积与归一化都了解，但是SiLU激活函数并没有了解过，遂搜索。  
> 搜索发现，SiLU函数是"x*sigmoid(x)"，用于提高模型非线性表达能力。  
> 函数式为 x/(1+e^-x)  

了解这三样基本组成单元后就可以构建，三者都可以通过nn.来调用，然后经搜索，可以用nn.Sequential方法将几层聚合成为一个，调用时按照函数来用就行。如此，就可以再将ConvModule打包成一个函数来直接调用。  

#### CSPLayer_2Conv

是十分复杂的一个单元。  
输入很简单，就是一个布尔量add以及一个求和数n，只是内部复杂。  

在进入后，首先经过一个ConvModule，然后**就不太明白**：输出的应该只有一个c_out维，但是图上还另外分了0.5c_out给concat，以及一整个c_out维给split。  
搜索的结果说是只有一个出口，进入split，可是图中明明是两个。所以这里今天没能搞懂。  

继续往下，先用pass完成需要完成的函数占空，然后整体先构建起来。发现不知道“n=3*d”中d参数如何获取，也是一个问题。今天先这样结束。  

**5.8**  
***

关于昨天的第一个问题，查找资料得到yolov8的这张结构图有两种，原理一致，只是手册里这版的Neck和Head层在另一版里合成了一层。  

分析两图结构相同之处以及要表达的意义，再结合最后一层输入的形状0.5(n+2)cout，可以猜测手册里的这一版应该是代表将第一层输入完整的送到concat，只是表达的方式不好。  
这样就能够匹配上最后的形状，同时在意义上也实现了最后与原数据的concat。  

#### SPPF

这一层的detial中没有给定输出维度，在架构图中分析，发现其输入输出是同维的，所以根据输入给定输出即可。  

detial中的MaxPool2d层没有给定任何参数，但是查询nn.MaxPool2d的用法时发现其是需要参数的：  
> kernel_size: 池化窗口大小  
> stride: 步长（默认等于 kernel_size） 
> padding: 边缘补零  

由于可能是自定义，也可能是一个约定俗成的大小，继续搜索这一模块在yolov8中的特定用法，果然是在SPPF层的特定用法，具体参数是固定的，分别是kernel_size=5, stride=1, padding=2。  

这样写的意义要从SPPF这一层的作用说起。SPPF是“SPP Fast”的缩写，意思是“快速感受野拓展”，比SPP更轻量、快速，通过多个MaxPool池化级联、最后再和原始输入拼接来增加感受野与提取上下文信息。  
而参数设置成5,1,2的关键就在于可以保持输入与输出同维，使MaxPool可以在多层级联中复用。  

依然将其封装为可调用的函数。  

#### 返回结构

基本构建好forward函数，但是返回值的结构并不很清晰，是作为列表、字典或者元组？  
到时候到调用的地方查看一下即可，现在先空着。  

#### 调试验证

根据结构图编写完**Backbone**部分，接下来是用调试方法检验正确性。  
由于之前使用过gdb，所以对于pdb的操作有一定的接受性，根据教程在forward函数开头下断点，运行时却直接报了**Neck**部分的未编译错误。可能是因为要先将所有模块初始化后才会执行，将断点设在init函数开头，再次执行，发现的确在**Backbone**对象的初始化完毕后继续初始化Neck部分。所以只好先继续完成其余模块。  

其实这里也看出来心急之处，明明报错信息是init函数未编译，但是却将forward部分也一并补全了，最后还一时半会debug不了:(。  

此外，在这里利用调试还可以解决之前的另一个问题，也就是CSPLayer层的输入中，关于层数，其与模型参数d是有关的，但是给定的初始参数中没用过的只有n，而不是d。其实这里也就可以大胆判定n就是3xd，在调试模式用`p n`来查看n的值，为1。这的确是3xd。所以照此补全即可。  
（在后面看到*yolomodel.py*文件时，其注释也提到了“*note that n = 3 x d*”，所以考究的结果是正确的。）  

### Neck

紧接着是Neck部分代码的编写。  
虽然前面提到了心急，直接一整个模块编完，但是其实一整个编完也没有什么问题。  

5.11先到这里
***

#### Upsample

发现Neck部分有两个上采样模块，并且作用都是让长、宽的分辨率增加一倍。  
查询nn中的上采样方法，有两种：  
> 一种是作为模块使用的nn.Upsample，就像Conv2d一样  
> 另一种是作为函数式使用的nn.functional.interpolate，更灵活  

因此沿袭上面的思路，还是要定义成一个个函数来使用更好，所以使用第二种来包装成函数。  

#### 模块函数复用

之前的模块都定义在**backbone.py**中，在这里依然要复用其中的函数。  
使用`from xxx import xxx`，在后面会发现提示模块未找到，经查，发现这是因为python的包结构的问题，需要使用相对路径。由于已经有init模块，用相对路径即可。  

#### 输出格式

注释中的C、X、Y、Z在原理图中并没有明确的指出是哪几个，发现原图中只向**Head**模块输出了三个，可能是X、Y、Z？  
再分析detial，有四个有名字的节点，是TopdowmLayer的1与2，以及BottomupLayer的0与1，对应一下形状，发现的确可以。  
也就是说，C->TopdowmLayer2，X->TopdownLayer1，Y->BottomupLayer0，Z->BottomupLayer1。  

由于依然没有运行到这里，所以具体的形式和Backbone一样依然未知。  

#### 运行

这次没有报后面编译error，反而是日志提示新模型被创建后，报了一个“*ValueError: Image file in subset not exists: /Mars_Assignment_Running/mar20/images/2490.jpg*”的值错误。  

可是数据集中明明有2490的，也许是dl(dataloader)模块有问题，在出错误模块开头添加断点，进行pdb调试。  

盯了一会，发现是低级错误，在**c1.py**中的*imageDir*定义时写成了绝对路径，所以在根目录找，肯定找不到。同样的，下一行的注释路径也写成了绝对路径，低级错误。  

终于，再次运行，提示"*NotImplementedError: YoloModel::freezeBackbone*"，这是一个定义在**yolomodel.py**中的自定义错误，提示freezeBackbone模块没有完成。  

### freezeBackbone

通过调试功能，定位freezeBackbone，发现其是在**base.py**中的preEpochSetup函数中被使用的，并且是一对，分别是*freezeBackbone*和*unfreezeBackbone*，同时分配有一个布尔标志位：self.backboneFreezed，在freeze时为True，在unfreeze时为False。  

以上是从代码结构进行的分析，但是preEpochSetup有什么用，是“提前批量数据建立”吗？freezeBackbone是暂时停止Backbone层的操作吗，如果是的话又为什么这么做？  
这些问题在结构图中并没有过说明，需要自己去搜寻。  

直接搜索preEpochSetup，可知其是一个社区的常用命名，一般用法如下：  
> 更新学习率；重置统计数据；打乱数据集；打印日志；清空GPU缓存等  

浏览preEpochSetup的代码，以及实时调试，其似乎实现了一个输入模型与要用到的一批数据，然后对数据内符合freezeBackbone标准的数据进行匹配，修改模型的freezeBackbone有关。这样看还是云里雾里，不明白这是什么意思。  

搜索freezeBackbone，得到其作用：  
> 用于冻结模型主干（backbone）参数的方法，这样在训练过程中，主干部分的权重不会更新，只训练其他部分（比如检测头）。这通常用于迁移学习，当希望利用预训练特征提取器时非常有用。  
> 在 YOLOv8 中的作用是当主干网络（比如 CSPDarknet）已经在大数据集（如 COCO）上预训练好了，如果想用用自己的小数据集做 fine-tuning，冻结主干可以减少训练时间、减少过拟合、保持特征提取能力
	> fine-tuning是指微调，是在已有模型的基础上进行少量训练以适应新需求的策略   

可见freezeBackbone的作用更多的是利于后面的小样本增量学习、知识蒸馏的应用。  

整合以上的信息，可以知道freeze与unfreeze的内部规律。  

5.12
***

freezeBackbone会令模型主干层中的超参数停止更新，相应的，unfreezeBackbone会恢复，具体的应用是配合freezeBackboneEpoch这一概念，在大量数据预训练得到的初始模型下，用小的数据集进行微调、改变相关超参数时会产生“灾难性遗忘”，忘记之前在大数据下的表现，并对小数据集过拟合。  
所以需要设置在小批量数据训练开始前先冻结主干，只修改其他部分的参数，等到梯度稳定、模型适应后，在后续训练批次才允许修改，即unfreezeBackbone。这样也能提高训练速度。  

更具体的，避免某一模块的超参数更新，可以先遍历该模块的所有层，将其设为`requires_grad = False`来使其不接受梯度反向传播，达到不更新数据，“freeze”的效果。  

5.13
***

但是"requires_grad"的值想要被修改，该变量必须要能被.parameter方法注册为类成员。  
也就是说我的这些模块需要定义在Backbone的init中，需要将他们模块化。而目前的方式是函数式，所以要想实现，还需要重构。  
> 当前的函数式有两个问题：
	> 第一是运行时构造并立即执行模块，导致无法在 init()中提前注册模块，也就不能使用 .parameters() 或 .to(device) 等 PyTorch 机制；  
	> 另外是为了方便，函数实现与输入紧绑定，也就是建立在输入张量已知的情况下，所以也没有办法在init中先建立。这涉及到一个核心思想：模块设计必须与数据无关（即不要依赖运行时的输入数据 shape）  

在重构中，函数转为模块，依然是继承nn.Module建立一个新类，然后建立初始化与前向传播函数，按照原有逻辑重新写一写即可，这样封装成一个个模块，被注册后就能用`self.backbone.requires_grad = False`冻结。  

重构完成后，同样地在**neck.py**中也对应的修改。  

debug：  
+ 初始化对父类时要用`super().__init__()`而不是`super.__init()`，细节问题  
+ 在初始化时，“nn.Conv2d(c_in, c_out, k, stride=s, padding=p)”报错，显示TypeError。搜索一番，意思是我输入的不是整数，有浮点数，不接受。于是通过pdb在这里打断点，然后依次打印，发现是*c_out*为浮点，是16.0。将其转换为int即可。  
+ 同样的，下一个nn.BatchNorm2d(c_out)也是同样的错误，所以干脆在开头就将其变为int类型。  
+ 同样地，后面c_in也会出问题，所以也一样转为int  

#### 重构后运行

这次十分顺利，到达了之前空着不知道返回值如何打包的地方。  
观察报错信息为“_, feat1, feat2, feat3 = self.backbone.forward(x)  
TypeError: cannot unpack non-iterable NoneType object
”  

也就是说要接收的是四个，直接四个一起返回即可，不用什么包装  
> python默认支持多返回值，会打包成为一个元组  

补全backbone与neck的输出后，继续运行，这次是自己实现的Upsample：“return nn.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)  
AttributeError: module 'torch.nn' has no attribute 'interpolate'”  

查找可得，也是因为细节问题：应用`nn.functional.interpolate`而不是`nn.interpolate`，修改细节即可。  

### Debug例子

喜闻乐见的debug时间。  
报错信息为“RuntimeError: Given groups=1, weight of size [128, 384, 1, 1], expected input[16, 1152, 40, 40] to have 384 channels, but got 1152 channels  instead”  

说明是有一个地方ConvModule输入不对劲。先在ConvModule的forward中设置断点，一直continue，果然后续也出现了这个问题。但是由于基本每个模块都会调用，不好定位，很容易跟丢。  

所以采取另一种方式，也就是用print，在每一层的前向传播时打印预期输入与实际输入，这样在哪里出错就可以分析出来，于是在ConvModule实现：  
![2](pictures/2.png)  

但是依然有些太多了，既然Conv是一个基础模块，那么在高级模块打印呢？于是在CSPLayer中进行这个操作，再次输出：  
![3](pictures/3.png)  
这次就十分清晰了，在第五个CSPLayer不一致，是在neck部分的TopDownlayer2。  

于是在此处设置断点，分析实际输入：  
![3](pictures/4.png)  
比理论大了三倍，那么是backbone的输出有问题。

将断点移到backbone处，发现问题出在最后一层：  
![3](pictures/5.png)  
理论形状为256，但是实际上是1024，出了问题。处问题的是SPPF模块，对照，发现是漏了一个模块。粗心！  

补全后继续运行，看到了令人安心的“NotImplementedError: DetectionLoss::\_\_call\_\_”  

5.14的工作到此结束～  
***  

### DetectionLoss

错误信息是在**loss.py**中的Detection类的\_\_call\_\_函数，首先研究一下它是什么用：  
> \_\_call\_\_ 的作用就是让一个类的实例表现得像一个函数，适用于需要状态和行为结合的场景。
> 具体的，其会让更简洁，比如建立了一个module，如果用类来完成forward，会写的繁琐，而用这个特性直接用类调用  

然后再分析这个类是用来做什么的。搜索得：  
> DetectionLoss 是 YOLOv8 中的损失函数类，负责在训练时根据模型输出和真实标注计算总损失。  

整个过程是  
1. 先初始化三个损失项，分别是边框box损失、分类cls损失、分布式回归DFL损失  
> box损失：衡量模型预测的边界框位置与真实框之间的差异，通常用一种IoU Loss的方式  
> cls损失：衡量模型预测的目标类别与真实类别是否一致，用于惩罚预测错误的概率分布  
> DFL损失：YOLOv8 使用了分布式回归（DFL）来预测边界框，不再直接预测数值，而是预测某个离散分布，DFL 就是衡量这个分布与真实数值的差异，是一个改进  
2. 预测预处理，最终得到的predBoxDistribution是所有预测点的回归分布（用于计算 box）；得到的predClassScores是所有预测点的类别分布（用于计算分类损失）  
3. 标签预处理，将原始标签转换成训练所需格式  
4. 损失计算部分，这里需要补全  
5. 最后再对三类损失加权求和，得到最终总损失  

损失计算部分有点困难，代码好复杂。。。  
首先根据结构，可以分析出这里肯定是写成`loss[n] = self.xxxx(xxxx)`这样的利用内置方法来完成上述几种损失的获取。  

loss[0]就是box损失，发现上面有BboxLoss模块可以利用，在init中也定义的有，所以用它的forward应该能计算出。再看forward的内部，不光计算了代表box的iou损失，还利用DFL模块计算了代表DFL的损失，最后输出两项损失。所以可以按这个格式完成两个损失。  

但是forward有好多复杂且看不懂的参数，借助翻译与AI工具进行分析：  
+ pre_dist：是每个预测点输出的每个边界（左、上、右、下）对应的分布，这个会在DFL损失使用。应该就是有三个的preds，并以为这也是一一对应的，索引为二。可是发现preds的三个并不是与损失对应的，而是三个尺度方面的特征图，所以可以先整个放进去。  
+ pred_bboxes：这个是用于解码的框坐标，具体是因为预测坐标是基于**锚点**的相对偏移量，要想获得真实图像上的框坐标就还要进行一个解码，得到的会用来计算IoU损失。根据搜索得到的张量形状与上述分析，猜测可能是预处理部分得到的gtBboxes.  
+ anchor_points：这个是锚点，也就是有了这个才能解码。但是并没有找到显式的锚点
+ target_bboxes：每个预测点分配到的 GT 框，在 assigner 中分配的，这里应该是用TaskAlignedAssigner模块来获取。再次研究**tal.py**中的这个模块，仍然是最终都集中到forward里，然后输出四个值，似乎都挺有用，可以先跑一下。这个的输入就很明显，用已有的。其中锚点不知道用什么。
+ target_scores：是每个预测点的标签分布，在 bbox loss 中用于加权。上一步得到了。
+ target_scores_sum：其实是target_scores.sum()，用于归一化所有loss。
+ fg_mask：标记哪些哪些预测点是前景（参与 loss），也得到了。  

现在的情况是锚点未知、前几个参数不确定。  

#### 锚点

查找锚点，发现一般会存储在self.model.anchor_points这样的变量中，但具体是未知的，所以debug一下，看有没有这用法。  

![3](pictures/6.png)  

发现是有的！  
